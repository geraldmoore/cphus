name: Scheduled Scraper

permissions:
  contents: write
  
on:
  schedule:
    - cron: '*/30 * * * *'
  workflow_dispatch:

jobs:
  run-scraper:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
    
    - name: Install uv
      uses: astral-sh/setup-uv@v4
      with:
        enable-cache: true
    
    - name: Set up Python
      run: uv python install 3.12
    
    - name: Install dependencies
      run: uv sync
    
    - name: Run scraper script
      env:
        BOLIGSIDEN_URL: ${{ secrets.BOLIGSIDEN_URL }}
        BOLIGPORTAL_URL: ${{ secrets.BOLIGPORTAL_URL }}
        FIRECRAWL_API_KEY: ${{ secrets.FIRECRAWL_API_KEY }}
        DISCORD_BOT_TOKEN: ${{ secrets.DISCORD_BOT_TOKEN }}
        DISCORD_CHANNEL_ID: ${{ secrets.DISCORD_CHANNEL_ID }}
        GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
      run: |
        uv run main.py
      timeout-minutes: 10
    
    - name: Commit and push changes
      run: |
        git config --local user.email "github-actions[bot]@users.noreply.github.com"
        git config --local user.name "github-actions[bot]"
        git add data/listings.parquet
        git diff --staged --quiet || git commit -m "Update listings data - $(date -u +'%Y-%m-%d %H:%M:%S UTC')"
        git push
      continue-on-error: false
